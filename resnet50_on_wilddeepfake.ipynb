{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install webdataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hpz-UjwrQgTx","outputId":"46b65705-1764-44b7-a3b3-f0b58ec2d9c4","trusted":true,"execution":{"iopub.status.busy":"2025-08-14T11:26:31.350184Z","iopub.execute_input":"2025-08-14T11:26:31.350500Z"}},"outputs":[{"name":"stdout","text":"Collecting webdataset\n  Downloading webdataset-1.0.2-py3-none-any.whl.metadata (12 kB)\nCollecting braceexpand (from webdataset)\n  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from webdataset) (1.26.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from webdataset) (6.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->webdataset) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->webdataset) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->webdataset) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->webdataset) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->webdataset) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->webdataset) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->webdataset) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->webdataset) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->webdataset) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->webdataset) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->webdataset) (2024.2.0)\nDownloading webdataset-1.0.2-py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import kagglehub\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torchvision import datasets, models\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score\nfrom PIL import Image\nimport torch.nn.functional as F\nimport random\nfrom huggingface_hub import hf_hub_url, HfFileSystem\nimport webdataset as wds\nimport io\n","metadata":{"id":"XR8DNGKCQFAf","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJTHB6pMQU7A","outputId":"a7d0382e-0ad3-419e-b41a-a29f7580babd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"execution_count":3},{"cell_type":"code","source":"# 6. Load pretrained ResNet-50 and modify final layer\nmodel = models.resnet50(pretrained=True)\n\n# Freeze all layers initially\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace final fully connected layer (for 2 classes)\nmodel.fc = nn.Linear(model.fc.in_features, 2)\n\n# Only the final layer's parameters are trainable for now\nfor param in model.fc.parameters():\n    param.requires_grad = True\n\nmodel = model.to(device)\n\n# 7. Loss and optimizer (only parameters with requires_grad=True are updated)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OShVuz3hQZqB","outputId":"baff1c02-88a9-487a-8dbb-9dcbad04b4de"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"execution_count":38},{"cell_type":"code","source":"# 44444\ndef openImgaes(images):\n    pil_images = []\n    for img_bytes in images:\n        if isinstance(img_bytes, bytes):\n            # Convert bytes to PIL Image\n            pil_img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n            pil_images.append(pil_img)\n        else:\n            # If already PIL image, just append\n            pil_images.append(img_bytes)\n\n    # Now apply your transforms\n    input_tensors = torch.stack([predict_transform(img) for img in pil_images])\n\n\n    return input_tensors","metadata":{"id":"SRyVzHFmdlgq"},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# 444\npredict_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])\n","metadata":{"id":"ZFciyOgvdxTX"},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# 8. Training function\ndef train_model(model, train_dataset, val_dataset, epochs=5, device='cuda'):\n    model.to(device)\n    optimizer = torch.optim.Adam(model.parameters())\n    criterion = torch.nn.CrossEntropyLoss()\n\n    for epoch in range(epochs):\n        train_loader = DataLoader(train_dataset, batch_size=32)\n\n        model.train()\n        total_loss = 0\n        batch_count = 0\n        for inputs, labels in train_loader:\n            newInputs = openImgaes(inputs)\n            newInputs = newInputs.to(device)\n            labels_tensor = labels_to_tensor(labels).to(device)\n\n            optimizer.zero_grad()\n            outputs = model(newInputs)\n            loss = criterion(outputs, labels_tensor)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            batch_count += 1\n\n        avg_loss = total_loss / batch_count\n        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n\n        # Validation\n        model.eval()\n        all_preds = []\n        all_labels = []\n        val_loader = DataLoader(val_dataset, batch_size=32)\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                newInputs = openImgaes(inputs)\n                newInputs = newInputs.to(device)\n                labels_tensor = labels_to_tensor(labels).to(device)\n                outputs = model(newInputs)\n                _, preds = torch.max(outputs, 1)\n                all_preds.extend(preds.cpu().numpy())\n                all_labels.extend(labels_tensor.cpu().numpy())\n\n        acc = accuracy_score(all_labels, all_preds)\n        print(f\"Validation Accuracy: {acc*100:.2f}%\\n\")\n","metadata":{"id":"zRXNgJT9bVI3"},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# 444\ndef labels_to_tensor(labels):\n    label_to_idx = {\n      \"fake\": 0,\n       \"real\": 1\n    }\n    # labels is iterable of strings\n    numeric_labels = [label_to_idx[l] for l in labels]\n    return torch.tensor(numeric_labels, dtype=torch.long)","metadata":{"id":"awVMXRnoeEFa"},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def unfreeze_model(model, unfreeze_from_layer=6):\n    # ResNet layers: layer1, layer2, layer3, layer4\n    # unfreeze_from_layer: number between 1 and 4 to unfreeze from that layer onwards\n    layers = [model.layer1, model.layer2, model.layer3, model.layer4]\n\n    for param in model.parameters():\n        param.requires_grad = False  # Freeze all first\n\n    for param in model.fc.parameters():\n        param.requires_grad = True  # Always train final fc layer\n\n    # Unfreeze from specified layer onwards\n    for i in range(unfreeze_from_layer - 1, len(layers)):\n        for param in layers[i].parameters():\n            param.requires_grad = True\n\n    print(f\"Unfroze layers from layer{unfreeze_from_layer} onwards\")","metadata":{"id":"mhlk20_rSAyk"},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# 13. unfreeze deeper layers to fine-tune\nunfreeze_model(model, unfreeze_from_layer=3)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YX3TMyEyQd7C","outputId":"5736e12d-b5ad-471b-e892-dd05ea82be2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unfroze layers from layer3 onwards\n"]}],"execution_count":11},{"cell_type":"code","source":"# 444\nfrom torch.utils.data import DataLoader\n\ndef get_label_from_key(key_str):\n\n    if 'fake' in key_str:\n        return 'fake'\n    elif 'real' in key_str:\n        return 'real'\n    else:\n        return 'unknown'\n\ndef preprocess(sample):\n    image = sample.get('png') or sample.get('jpg') or sample.get('tiff')\n    key = sample.get('__key__', '')\n    label = get_label_from_key(key)\n    return image, label\n","metadata":{"id":"1wyuOwK-Q4yw"},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Replace \"your_own_huggingface_token\" with your actual Hugging Face access token\n# Get one at: https://huggingface.co/settings/tokens\nmyTtoken = \"your_own_huggingface_token\"\n\nos.environ[\"HF_TOKEN\"] = myTtoken   \n    \"train_fake\": \"**/fake_train/*.tar.gz\",\n    \"train_real\": \"**/real_train/*.tar.gz\",\n    \"test_fake\":  \"**/fake_test/*.tar.gz\",\n    \"test_real\":  \"**/real_test/*.tar.gz\"\n}\n\ndef get_urls(split_pattern):\n    fs = HfFileSystem()\n    files = [fs.resolve_path(path) for path in fs.glob(\"hf://datasets/xingjunm/WildDeepfake/\" + split_pattern)]\n    return [hf_hub_url(file.repo_id, file.path_in_repo, repo_type=\"dataset\") for file in files]\n\ndef make_ds(urls):\n    urls_pipe = f\"pipe: curl -s -L -H 'Authorization: Bearer {myTtoken}' {'::'.join(urls)}\"\n    return wds.WebDataset(urls_pipe, shardshuffle=False).decode()\n","metadata":{"id":"M-8IDsuQRBm3"},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_fake_urls = get_urls(splits[\"train_fake\"])\ntrain_real_urls = get_urls(splits[\"train_real\"])\ntest_fake_urls  = get_urls(splits[\"test_fake\"])\ntest_real_urls  = get_urls(splits[\"test_real\"])\n\nrandom.seed(42)  # For reproducibility\nrandom.shuffle(train_fake_urls)\nrandom.shuffle(train_real_urls)\nrandom.shuffle(test_fake_urls)\nrandom.shuffle(test_real_urls)","metadata":{"id":"m0W9eEZXRKgU"},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(len(train_fake_urls), len(train_real_urls), len(test_fake_urls), len(test_real_urls), sep='\\n')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xudbzm3VTBnK","outputId":"6f63c210-c6ae-4989-f841-ae3590ca6e62"},"outputs":[{"output_type":"stream","name":"stdout","text":["592\n","371\n","115\n","42\n"]}],"execution_count":null},{"cell_type":"code","source":"max_samples_training =4000\nmax_smaples_test= 2000","metadata":{"id":"YkZu_JSvVoTq"},"outputs":[],"execution_count":17},{"cell_type":"code","source":"fake_data_set = []\nmax_samples_per_url = 70\nfor url in train_fake_urls:\n  if len(fake_data_set) >= max_samples_training:\n    break\n  train_fake =make_ds([url])\n  train_fake_processed = list(train_fake.map(preprocess))\n  random.shuffle(train_fake_processed)\n  for image,label in train_fake_processed:\n    if len(fake_data_set) >= max_samples_training:\n      break\n    fake_data_set.append((image,label))\n\nfake_train = fake_data_set\nrandom.shuffle(fake_train)\n","metadata":{"id":"l8VTCLX7VPvq"},"outputs":[],"execution_count":29},{"cell_type":"code","source":"real_data_set = []\nmax_samples_per_url = 140\nfor url in train_real_urls:\n  if len(real_data_set) >= max_samples_training:\n    break\n  train_real =make_ds([url])\n  train_real_processed = list(train_real.map(preprocess))\n  random.shuffle(train_real_processed)\n  for image,label in train_real_processed:\n    if len(real_data_set) >= max_samples_training:\n      break\n    real_data_set.append((image,label))\n\n\nreal_train = real_data_set\nrandom.seed(5)\nrandom.shuffle(real_train)\n","metadata":{"id":"J5AspE_fYoXd"},"outputs":[],"execution_count":30},{"cell_type":"code","source":"_test_fake_data_set = []\nmax_samples_per_url = 180\nfor url in test_fake_urls:\n  if len(_test_fake_data_set) >= max_smaples_test:\n    break\n  test_fake =make_ds([url])\n  test_fake_processed = list(test_fake.map(preprocess))\n  random.shuffle(test_fake_processed)\n  for image,label in test_fake_processed:\n    if len(_test_fake_data_set) >= max_smaples_test:\n      break\n    _test_fake_data_set.append((image,label))\n\n\n\nrandom.seed(13)\nrandom.shuffle(_test_fake_data_set)\n\ntest_fake_data_set,fake_val = _test_fake_data_set[:int(len(_test_fake_data_set)*0.5)], _test_fake_data_set[int(len(_test_fake_data_set)*0.5):]\n\nrandom.shuffle(test_fake_data_set)\nrandom.seed(100)\nrandom.shuffle(fake_val)","metadata":{"id":"mpjCHMkxZNOS"},"outputs":[],"execution_count":28},{"cell_type":"code","source":"train_set = fake_train + real_train\ntest_set = test_real_data_set + test_fake_data_set\nval_set = fake_val + real_val\n\nrandom.seed(58)\nrandom.shuffle(train_set)\nrandom.seed(1)\nrandom.shuffle(test_set)\nrandom.seed(99)\nrandom.shuffle(val_set)","metadata":{"id":"nx71UaStaRUq"},"outputs":[],"execution_count":32},{"cell_type":"code","source":"_test_real_data_set = []\nmax_samples_per_url = 500\nfor url in test_real_urls:\n  if len(_test_real_data_set) >= max_smaples_test:\n    break\n  test_real =make_ds([url])\n  test_real_processed = list(test_real.map(preprocess))\n  random.shuffle(test_real_processed)\n  for image,label in test_real_processed:\n    if len(_test_real_data_set) >= max_smaples_test:\n      break\n    _test_real_data_set.append((image,label))\n\n\nrandom.seed(67)\nrandom.shuffle(_test_real_data_set)\n\ntest_real_data_set,real_val = _test_real_data_set[:int(len(_test_real_data_set)*0.5)], _test_real_data_set[int(len(_test_real_data_set)*0.5):]\nrandom.shuffle(test_real_data_set)\n\nrandom.seed(87)\nrandom.shuffle(real_val)","metadata":{"id":"LHeVxxHMZNoR"},"outputs":[],"execution_count":31},{"cell_type":"code","source":"train_model(model, train_set, val_set,epochs=4)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ziHAH7G5bKHb","outputId":"5c2a4142-640f-452d-a9dd-0f0a724f4e07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/4], Loss: 0.1974\n","Validation Accuracy: 86.80%\n","\n","Epoch [2/4], Loss: 0.0695\n","Validation Accuracy: 81.60%\n","\n","Epoch [3/4], Loss: 0.0493\n","Validation Accuracy: 81.20%\n","\n","Epoch [4/4], Loss: 0.0399\n","Validation Accuracy: 80.40%\n","\n"]}],"execution_count":39},{"cell_type":"code","source":"model.eval()\nall_preds = []\nall_labels = []\nval_loader = DataLoader(test_set, batch_size=32)\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        newInputs = openImgaes(inputs)\n        newInputs = newInputs.to(device)\n        labels_tensor = labels_to_tensor(labels).to(device)\n        outputs = model(newInputs)\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels_tensor.cpu().numpy())\n\nacc = accuracy_score(all_labels, all_preds)\nprint(f\"test Accuracy: {acc*100:.2f}%\\n\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OM8Wb2DJ3gx-","outputId":"1229a0bf-e3e5-46fb-f0e1-ec77de037385"},"outputs":[{"output_type":"stream","name":"stdout","text":["test Accuracy: 80.80%\n","\n"]}],"execution_count":40},{"cell_type":"code","source":"print(model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqrEOb7X40bk","outputId":"127a176e-3c92-48f6-e0f3-d09a344a755c"},"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",")\n"]}],"execution_count":41}]}